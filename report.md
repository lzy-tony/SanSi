# SanSi

> 三思而后行。

## 简介

### 介绍

三思（SanSi）是一个新型迭代哈希密码，可以接收输入的字符串并将其哈希为 `80` 位的字符串。

不同于传统顺序处理的 sponge 结构，三思在其基础上引入了更多的复杂性：将顺次线性处理分块的结构改变为树形结构，通过在处理顺序的维度引入更多的复杂性（在每次读入时不直接顺序处理而是在积累了一定数量后以树形结构的方式进行处理，即“**三思而后行**”）加强了密码，使得长度扩展攻击等攻击方法更加困难。同时，三思还在 `f` 函数处引入了不同的方法。

本算法由刘方舟、刘子君、刘泽禹、庞元喆、徐明启设计、实现并完成评估。



### 使用方法

#### demo

如果要运行 `demo`，可以在文件夹下 `make all` 并运行 `./main <arg1> <arg2>`。其中 `<arg1>` 与 `<arg2>` 为输入输出文件地址。输入文件中以若干行分割若干组需要哈希的字符串。



#### 使用

可以通过在自定义程序中引用 SanSi 算法头文件、并在编译时进行链接进行使用，具体示例如下。

```cpp
#include "sansi.h"

#include <iostream>
#include <cstdio>
#include <cstring>

using namespace std;

int main() {
    Sansi crypto; // 定义
    uint64_t *src;
    
    ...
    crypto.add_block(src); // 添加一个1024位的分块
    cout << crypto.hash() << endl; // 输出哈希结果
    ...
    
    return 0;
}
```



## 设计理念

在哈希函数密码一类问题中，哈希函数 $h$ 需要将无穷域上的输入映射到固定长度上。因此，多数哈希函数密码采用迭代的方式对此进行处理。传统的迭代结构，如 Merkle-Damgard 结构、sponge 结构尽管有所不同，但均采用了顺序执行的方式，即依次处理将数据流嵌入状态中，最终再依据状态进行输出。

在这样的背景下，我们考虑在处理顺序的维度上引入更多的复杂性，通过树形结构而非线性结构处理数据。此时，当我们通过黑盒的视角来观察哈希函数 $h$ 和加密的字符串时，其具体结构会更加不可知，并难以被攻击。

在这一想法的基础上，我们的工作集中于：

- 设计一个合理的计算顺序规则，使得对于不同的字符串输入 $h$ 能够将其以较为混乱的顺序进行处理，并且保证同一个字符串的处理顺序是一定的。
- 将字符串分块的位置信息内嵌入 `f` 函数中，使得攻击者无法通过仅仅调换两个分块的顺序找到碰撞。

我们算法设计的最终结果采取了等待输入积累了一定组数的分组后再进行树形合并处理的方式。在我们看来，这一过程就好比“三思而后行”的过程（积累、再执行），与传统迭代结构中“直接行动”的范式相区别。因此，我们将我们的设计理念融入算法的名称当中，命名其为“三思”。



## 算法组成

### 算法流程

算法的基本流程如下图。

![](./img/flowchart.jpg)



### 迭代结构

sponge 结构的函数主要是由内存状态 $S$、转换函数 $f$ 和填充函数 $P$ 构成的。本算法的树形迭代结构与其有一定的相似之处。在本节中，我们围绕内存状态、树形处理和输出结果三个部分介绍本算法的迭代结构，转换函数 $f$ 和填充函数 $P$ 将在其它章节中进行详细介绍。



#### 内存状态

与采用 sponge 结构的 SHA3 类似，SanSi 采用了大小为 `1600` 比特的内存状态，并将其组织成为一个 $5 \times 5 \times 64$ 的三维张量的形式如下图所示。

![](./img/hash_tensor.jpg)

在 $S$ 中，我们可以通过三维下标 $s_{x, y, z}$ 对某一位进行索引。约定 $s_{x, y}$ 为一个 `64` 位的整数 $s_{x, y, 0} \dots s_{x, y, 63}$。

为方便起见，我们约定沿 $x$ 方向为一列、沿 $y$ 方向为一行。



#### 树形处理

##### 分组内嵌

与传统的线性处理结构不同，SanSi 引入了树形处理结构。约定 `1024` 比特为一个分组，`8` 个分组为一个大组。

对于每个分组输入，算法首先根据组的奇偶性进行判别：奇数位的组将与全0的内存状态相异或；偶数位的组将与全1的内存状态相异或（异或范围为 $S$ 的前 `1024` 比特）。异或后运行一次 `f` 函数进行打乱。



##### 启发值计算

对于每一个输入的块，我们通过其位置和内在信息计算出一个对应的权值作为启发值 $k$ 用于确定树形结构合并的计算顺序。令 $\text{pos}$ 为块在数据流中的位置，则有
$$
k = (\bigoplus \limits_{i = 0}^4 \bigoplus \limits_{j = 0}^4 s_{i, j}) \oplus \text{pos}
$$


##### 合并状态

在完成了每个分组的状态内嵌后，我们的算法得到了一系列的内存状态 $S$，此时需要将其进行合并。以 `8` 个分组为一个大组，每当读入一个完整的大组，依据启发值从大到小将当前的所有内存状态依次进行合并。对于内存状态 $S_1, S_2$，单次合并得到 $S^*$ 的流程为：

- 更新位置信息：
  $$
  \text{pos}^* = \lfloor \frac{\text{pos}_1 + \text{pos}_2}{2} \rfloor
  $$

- 更新内存状态：
  $$
  S^* = S_1 \oplus S_2
  $$

- 进行打乱：
  $$
  S^* = f(S^*)
  $$

- 重新计算启发值 $k$。

最终的合并顺序可视化后呈现树形结构。一种可能的合并示意图如下图所示。

![](./img/tree_structure.jpg)



#### 输出结果

与 sponge 结构类似，本算法采用了迭代输出的方式，在共计 `20` 轮中每轮输出四位 $s_{0, 0, 60} s_{0, 0, 61} s_{0, 0, 62} s_{0, 0, 63}$ 后再运行一次 `f` 函数。



### `f` 函数

#### 概述

在“设计理念”一节中，我们已经提到，由于树形结构与线性结构的不同，本算法的 `f` 函数还需要嵌入位置信息以避免攻击者通过简单调换两个分块的位置来制造碰撞。在这一节中，我们会通过介绍 `f` 函数的具体流程来说明这一目的是如何完成的。

具体而言，本算法的 `f` 函数中包含两轮，每一轮依次完成 $\sigma, \rho, \pi, \alpha, \chi$ 5个阶段。



#### $\sigma$ 阶段

$\sigma$（stencil）阶段使得每一位与其上下左右相邻的6位相互影响。

在这一阶段中，我们将 $s_{i,j}$ 的 `64` 位拆分为 `4` 个 `16` 位的整数，不妨设为 $t_{i, j, 0}, \dots, t_{i, j, 3}$。

对于任一 `8` 位整数，我们首先考虑对其进行7点模板计算（stencil），即
$$
t_{i, j, k} = g(t_{i - 1, j, k}, t_{i, j - 1, k}, t_{i, j, k - 1}, t_{i, j, k}, t_{i, j, k + 1}, t_{i, j + 1, k}, t_{i + 1, j, k})
$$
模板计算的内容与CRC校验和的思想类似，即将等式右侧的7个数值相加得到整数 $z$，如果 $z$ 超过 $l = 2^{16} - 1$，则对其进行校验和计算：

```pseudocode
while z > l:
	z <- z % l + z / l
```

为了计算的效率，我们将上述循环简化为固定进行三轮，再对 $l$ 取模（16位截断），即

```pseudocode
z <- z % l + z / l
z <- z % l + z / l
z <- z % l + z / l
z <- z % l
```

设这一过程为函数 $\text{CRC}'(z)$，该过程是非线性的。

同时，在 $\sigma$ 阶段中，我们引入位置信息，即
$$
t_{i, j, k} = \text{CRC}'(t_{i - 1, j, k} + t_{i, j - 1, k} + t_{i, j, k - 1} + t_{i, j, k} + t_{i, j, k + 1} + t_{i, j + 1, k} + t_{i + 1, j, k} + \text{pos} \times c)
$$
其中 $c$ 为一个固定常数。



#### $\rho$ 阶段

$\rho$（rotation）阶段为将 $s_{i, j}$ 的 `64` 位进行位移轮换。在 SHA3 算法 $\rho$ 阶段的基础上，我们将位置信息内嵌如了这一阶段。
$$
s_{i, j, k} = s_{i, j, (k - \frac{t(t - 1)}{2} + \text{pos})}
$$
注：此处的加减运算为模64意义下的。



#### $\pi$ 阶段

$\pi$（permutation）阶段为按行列顺序进行打乱。
$$
s_{3i + 2j, i} = s_{i, j}
$$


#### $\alpha$ 阶段

$\alpha$（and）阶段按列进行非线性的与运算和非运算打乱。每列与其模意义下 $\pm 2$ 的列进行运算，融入一定的非局部特征。
$$
s_{i, j, k} = s_{i, j, k} \oplus ((s_{i + 2, j, k}) \And (\lnot s_{i - 2, j, k}))
$$
注：此处的加减法为模5意义下的加减法。



#### $\chi$ 阶段

$\chi$（xor）阶段将一个轮常数通过异或的方式嵌入内存状态中。



### 填充

[TODO]



## 算法实现效率

### 测试方法

由于测试目标是算法实现效率，因此在测试时除去了 `IO` 时间与生成数据的时间，并且预先进行了两组数据的插入作为预热。

在具体测试框架中，代码总共处理了 `10000000` 个分块共 `10000000 * 1024` 位的数据，并结合运行时间计算出运行效率，具体代码见 `performance_test.cpp`。

上述流程可在 `make all` 后运行 `./performance_test` 完成。



### 测试结果

测试结果较为稳定，且程序运行效率约为 `534.551 Mbps`，在要求的 `500 Mbps` 以上。



## 评估结果

### 随机性检测

使用 [**NIST**统计学工具包](https://csrc.nist.gov/Projects/Random-Bit-Generation/Documentation-and-Software) 完成随机性检测。  

通过随机改动字节串中随机选取的部分比特，生成相近的多组明文，经过哈希后，获得待检测文件；之后使用**NIST**工具包对文件进行随机性分析。

上述流程可通过命令：

```bash
bash test.sh
```

完成。共生成 `10240` 组，长度为 `256` 个字符的随机相近明文，经过 SanSi 算法哈希并转换为 ASCII 编码的01串。

将待检测文件分为 `8` 个比特流，对其进行**NIST**工具包的所有随机性检测项目，结果显示，哈希结果通过了所有的随机性检测项目，如下表所示（具体检测结果文件详见 `/result/finalAnalysisReport_test1.txt`）：

|项目|P Value| 通过率 |
|:--:|:--:|:--:|
|Frequency| 0.118170 | 1/1 |
| BlockFrequency | 0.685931 | 1/1 |
|CumulativeSums| 0.236335/0.226213 |  2/2 |
| Rank | 0.346732 | 1/1|
| FFT | 0.977122 | 1/1 |
| Runs | 0.536981| 1/1 |
| LongestRun |0.518900 | 1/1|
|NonOverlappingTemplate| - | 148/148 |
| OverlappingTemplate | 0.673786 | 1/1 |
| ApproximateEntropy | 0.439917 | 1/1 |
| RandomExcursions | - | 8/8 |
| RandomExcursionsVariant | - | 18/18 |
| Serial | 0.955901/0.971477 | 2/2 |
| LinearComplexity | 0.300616 | 1/1 |



### 生日攻击检测

我们对算法进行生日攻击，攻击代码见 `birthday_attack.cpp`。

由于硬件设施和算力限制，我们最多仅进行到 $2^{26}$ 次哈希没有找到碰撞。



## 参考资料

1. 算法的结构参考了 SHA3 的结构。
2. 算法的软件实现参考了 [hash-library](https://github.com/stbrumme/hash-library) 仓库的实现方式。
3. 算法评估的随机性检测使用了 [**NIST**统计学工具包](https://csrc.nist.gov/Projects/Random-Bit-Generation/Documentation-and-Software)。
